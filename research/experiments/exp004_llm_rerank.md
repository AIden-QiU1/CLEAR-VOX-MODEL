# EXP-004: LLM N-besté‡æ’

> **çŠ¶æ€**: ğŸ”„ è®¡åˆ’ä¸­  
> **ä¼˜å…ˆçº§**: P1  
> **ä¾èµ–**: EXP-003  
> **é¢„è®¡æ—¶é—´**: 3-5å¤©

---

## å‡è®¾

ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹å¯¹ASRçš„N-bestå€™é€‰ç»“æœè¿›è¡Œè¯­ä¹‰é‡æ’ï¼Œå¯ä»¥åœ¨åå¤„ç†é˜¶æ®µè¿›ä¸€æ­¥é™ä½CER 10-20%ã€‚

## æ–¹æ³•

1. ASRç”Ÿæˆ Top-K (K=5~10) å€™é€‰ç»“æœ
2. ä½¿ç”¨LLMå¯¹å€™é€‰è¿›è¡Œè¯­ä¹‰æ‰“åˆ†
3. é€‰æ‹©è¯­ä¹‰æœ€åˆç†çš„ç»“æœä½œä¸ºæœ€ç»ˆè¾“å‡º

### LLMé€‰å‹
- **GPT-4**: æ•ˆæœæœ€å¥½ï¼Œæˆæœ¬é«˜
- **Qwen-72B**: ä¸­æ–‡æ•ˆæœå¥½ï¼Œæˆæœ¬ä¸­ç­‰
- **Qwen-7B**: æœ¬åœ°éƒ¨ç½²ï¼Œæˆæœ¬ä½

## é…ç½®

```yaml
asr:
  model: outputs/exp003/checkpoint_best  # æœ€ä½³å¢å¼ºæ¨¡å‹
  beam_size: 10  # ç”Ÿæˆ10ä¸ªå€™é€‰
  
llm_rerank:
  enabled: true
  model: qwen-72b  # or gpt-4, qwen-7b
  
  prompt_template: |
    è¯·ä»ä»¥ä¸‹æ„éŸ³éšœç¢æ‚£è€…çš„è¯­éŸ³è¯†åˆ«å€™é€‰ç»“æœä¸­ï¼Œé€‰æ‹©è¯­ä¹‰æœ€é€šé¡ºçš„ä¸€ä¸ªï¼š
    
    å€™é€‰ç»“æœï¼š
    {candidates}
    
    è¯·ç›´æ¥è¾“å‡ºæœ€åˆç†çš„ç»“æœï¼Œä¸è¦è§£é‡Šã€‚
    
  scoring:
    method: perplexity  # or ranking
    threshold: 0.8
    
  # æœ¬åœ°éƒ¨ç½²é…ç½®ï¼ˆå¯é€‰ï¼‰
  local_deployment:
    enabled: false
    engine: vllm
    model_path: /models/qwen-7b
```

## æ‰§è¡Œå‘½ä»¤

```bash
# Step 1: ç”ŸæˆN-bestå€™é€‰
python scripts/generate_nbest.py \
    --model outputs/exp003/checkpoint_best \
    --test_data data/cdsd/10h/test \
    --beam_size 10 \
    --output results/exp004/nbest/

# Step 2: LLMé‡æ’
python scripts/llm_rerank.py \
    --nbest_dir results/exp004/nbest/ \
    --llm qwen-72b \
    --output results/exp004/reranked/

# Step 3: è¯„ä¼°
python scripts/evaluate.py \
    --hypothesis results/exp004/reranked/output.txt \
    --reference data/cdsd/10h/test/text
```

## æ¶ˆèå®éªŒ

| å®éªŒID | LLMæ¨¡å‹ | å€™é€‰æ•°K | é¢„æœŸCER |
|--------|---------|---------|---------|
| 004a | æ— LLM (Top-1) | 1 | baseline |
| 004b | Qwen-7B | 5 | - |
| 004c | Qwen-72B | 5 | - |
| 004d | GPT-4 | 5 | - |
| 004e | Qwen-72B | 10 | - |

## é¢„æœŸç»“æœ

| æŒ‡æ ‡ | EXP-003åŸºçº¿ | ç›®æ ‡ | ç›¸å¯¹æå‡ |
|------|-------------|------|----------|
| CER | ~25% | ~22% | 10-15% |

## æˆæœ¬ä¼°ç®—

| LLM | å•æ¬¡è°ƒç”¨ | æµ‹è¯•é›†(1000æ¡) | æœˆåº¦é¢„ç®— |
|-----|----------|----------------|----------|
| GPT-4 | $0.03 | $30 | - |
| Qwen-72B | Â¥0.02 | Â¥20 | - |
| Qwen-7B (æœ¬åœ°) | å…è´¹ | å…è´¹ | GPUæˆæœ¬ |

## å®é™…ç»“æœ

ï¼ˆå¾…å®éªŒå®Œæˆåå¡«å†™ï¼‰

## å…³é”®å‘ç°

ï¼ˆå¾…å®éªŒå®Œæˆåå¡«å†™ï¼‰

## ä¸‹ä¸€æ­¥

- [ ] å®ŒæˆN-bestç”Ÿæˆ
- [ ] å¯¹æ¯”ä¸åŒLLMæ•ˆæœ
- [ ] è€ƒè™‘æœ¬åœ°éƒ¨ç½²æ–¹æ¡ˆ
- [ ] è¿›å…¥ EXP-005 ä¸ªæ€§åŒ–é€‚é…
