# ğŸ› ï¸ å·¥å…·ä¸èµ„æº

> æ„éŸ³éšœç¢è¯­éŸ³è¯†åˆ«ç ”ç©¶å¸¸ç”¨å·¥å…·

---

## ğŸ“¦ æ ¸å¿ƒæ¡†æ¶

| å·¥å…· | ç”¨é€” | é“¾æ¥ |
|------|------|------|
| **FunASR** | ASRè®­ç»ƒä¸æ¨ç† | [GitHub](https://github.com/modelscope/FunASR) |
| **ESPnet** | ç«¯åˆ°ç«¯è¯­éŸ³ | [GitHub](https://github.com/espnet/espnet) |
| **SpeechBrain** | è¯­éŸ³AIå·¥å…·åŒ… | [GitHub](https://github.com/speechbrain/speechbrain) |
| **Kaldi** | ä¼ ç»ŸASR | [GitHub](https://github.com/kaldi-asr/kaldi) |

---

## ğŸ¤ TTS/VC å·¥å…·

### æ¨èç”¨äºæ•°æ®å¢å¼º

| å·¥å…· | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|----------|
| **F5-TTS** | é›¶æ ·æœ¬å…‹éš† | å¿«é€Ÿç”Ÿæˆå¤šæ ·åŒ–è¯­éŸ³ |
| **CosyVoice** | é˜¿é‡Œå¼€æº | ä¸­æ–‡TTS |
| **VITS** | ç«¯åˆ°ç«¯ | é«˜è´¨é‡åˆæˆ |
| **StarGAN-VC** | å£°éŸ³è½¬æ¢ | æ¨¡æ‹Ÿå‘éŸ³é—®é¢˜ |

### å®‰è£…ç¤ºä¾‹
```bash
# F5-TTS
pip install f5-tts

# CosyVoice
pip install cosyvoice
```

---

## ğŸ“Š è¯„ä¼°å·¥å…·

| å·¥å…· | ç”¨é€” | å‘½ä»¤ |
|------|------|------|
| **jiwer** | CER/WERè®¡ç®— | `pip install jiwer` |
| **whisper** | éŸ³é¢‘è½¬å½• | `pip install openai-whisper` |
| **torchaudio** | éŸ³é¢‘å¤„ç† | `pip install torchaudio` |

### è¯„ä¼°ç¤ºä¾‹
```python
from jiwer import cer, wer

# è®¡ç®—CER
error_rate = cer(reference, hypothesis)
print(f"CER: {error_rate:.2%}")
```

---

## ğŸ”§ éŸ³é¢‘å¤„ç†

| å·¥å…· | ç”¨é€” |
|------|------|
| **librosa** | ç‰¹å¾æå– |
| **pydub** | éŸ³é¢‘æ ¼å¼è½¬æ¢ |
| **sox** | å‘½ä»¤è¡ŒéŸ³é¢‘å¤„ç† |
| **ffmpeg** | è§†é¢‘/éŸ³é¢‘è½¬ç  |

---

## ğŸ§  LLM å·¥å…·

| å·¥å…· | ç”¨é€” | API |
|------|------|-----|
| **OpenAI** | GPT-4é‡æ’ | openai |
| **Qwen** | ä¸­æ–‡LLM | dashscope |
| **vLLM** | é«˜æ•ˆæ¨ç† | vllm |

### N-besté‡æ’ç¤ºä¾‹
```python
from openai import OpenAI

def llm_rerank(candidates, context=""):
    client = OpenAI()
    prompt = f"""
    å¯¹ä»¥ä¸‹ASRå€™é€‰ç»“æœæŒ‰è¯­ä¹‰åˆç†æ€§æ’åº:
    {candidates}
    è¾“å‡ºæœ€å¯èƒ½æ­£ç¡®çš„ç»“æœã€‚
    """
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content
```

---

## ğŸ“ æ•°æ®å¤„ç†

| å·¥å…· | ç”¨é€” |
|------|------|
| **pandas** | æ•°æ®åˆ†æ |
| **tqdm** | è¿›åº¦æ¡ |
| **jsonlines** | JSONLå¤„ç† |
| **webdataset** | å¤§è§„æ¨¡æ•°æ®åŠ è½½ |

---

## ğŸ–¥ï¸ è®­ç»ƒå·¥å…·

| å·¥å…· | ç”¨é€” |
|------|------|
| **DeepSpeed** | åˆ†å¸ƒå¼è®­ç»ƒ |
| **PEFT** | LoRA/QLoRA |
| **wandb** | å®éªŒè¿½è¸ª |
| **tensorboard** | å¯è§†åŒ– |

### LoRAé…ç½®ç¤ºä¾‹
```python
from peft import LoraConfig, get_peft_model

lora_config = LoraConfig(
    r=8,
    lora_alpha=16,
    target_modules=["q_proj", "v_proj"],
    lora_dropout=0.1,
)
model = get_peft_model(model, lora_config)
```

---

## ğŸ”— æ¨èèµ„æº

- [Hugging Face ASR Models](https://huggingface.co/models?pipeline_tag=automatic-speech-recognition)
- [ModelScope è¯­éŸ³æ¨¡å‹](https://modelscope.cn/models?page=1&tasks=auto-speech-recognition)
- [OpenSLR æ•°æ®é›†](https://www.openslr.org/)
