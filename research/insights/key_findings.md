# 💡 核心发现与洞察

> 从34+篇论文中提炼的关键技术洞察

---

## 📌 核心发现汇总

### 1. 数据层面

| 发现 | 来源论文 | 影响 |
|------|----------|------|
| 合成数据 ≈ 真实数据效果 | Interspeech 2025 | 可用TTS大规模扩增数据 |
| 定制化增强优于通用增强 | ACL 2024 | 需要针对症状设计mask |
| 1小时个性化数据 > 10小时混合数据 | CDSD论文 | 个性化优先于规模 |

### 2. 模型层面

| 发现 | 来源论文 | 影响 |
|------|----------|------|
| 冻结Decoder训练更稳定 | ICASSP 2024 | 小数据微调策略 |
| LoRA rank=8 足够 | 多篇论文 | 降低显存需求 |
| MoE路由按严重度分组 | NAACL 2024 | 处理个体差异 |
| Perceiver-Prompt有效 | Interspeech 2023 | 隐式提示优于显式 |

### 3. 后处理层面

| 发现 | 来源论文 | 影响 |
|------|----------|------|
| LLM重排N-best有效 | ICASSP 2024 | 最高20%相对提升 |
| 多模态辅助分类 | Interspeech 2024 | 文本+音频联合 |

---

## 🔥 最重要的5个发现

### 1️⃣ 个体差异是核心挑战
> "不同构音障碍患者之间的错误模式差异，可能比患者与正常人之间的差异还大"

**应对策略**:
- 两阶段训练（通用→个性化）
- MoE路由按特征分组
- 少样本快速适配

### 2️⃣ 合成数据有效且可扩展
> "使用TTS合成的模拟构音障碍语音，与真实数据训练效果相当"

**应对策略**:
- 使用F5-TTS/CosyVoice生成
- 加入症状特定变换
- 多样化说话人

### 3️⃣ 冻结Decoder是稳定训练的关键
> "在小数据场景下，只训练Encoder的LoRA，冻结Decoder，可以防止过拟合"

**应对策略**:
- Decoder完全冻结
- Encoder添加LoRA (rank=8)
- 小学习率 (1e-5)

### 4️⃣ LLM后处理显著提升效果
> "使用LLM对ASR的N-best结果进行重排，CER可降低10-20%"

**应对策略**:
- 生成5-10个候选
- GPT-4/Qwen重排
- 结合语义打分

### 5️⃣ 声调损伤是中文特有挑战
> "普通话构音障碍患者的声调错误率远高于英语患者的音素错误"

**应对策略**:
- 声调增强loss
- 声调专用mask
- 声调后处理矫正

---

## 📊 技术选型建议

### 推荐技术栈

| 组件 | 推荐方案 | 备选方案 |
|------|----------|----------|
| **基础ASR** | Paraformer-large | Whisper-large |
| **微调方法** | LoRA (rank=8) | Full fine-tune |
| **数据增强** | F5-TTS + SpecAugment | CosyVoice |
| **后处理** | LLM N-best rerank | 语言模型浅融合 |

### 训练策略

```
阶段1: 预热 (warmup)
- 数据: 正常语音 + 合成数据
- 目标: 适应领域词汇

阶段2: 通用适配
- 数据: 全部构音障碍数据
- 目标: 学习通用错误模式

阶段3: 个性化
- 数据: 目标用户数据
- 目标: 适配个体特征
```

---

## 🔗 相关链接

- [数据增强论文](../papers/data_augmentation/README.md)
- [ASR适配论文](../papers/asr_adaptation/README.md)
- [LLM融合论文](../papers/llm_integration/README.md)
- [语音重建论文](../papers/speech_reconstruction/README.md)
