# ğŸ¯ ASRæ¨¡å‹é€‚é… (ASR Adaptation)

> **æ ¸å¿ƒé—®é¢˜**: å¦‚ä½•è®©é¢„è®­ç»ƒASRæ¨¡å‹é€‚é…æ„éŸ³éšœç¢è¯­éŸ³ï¼Ÿ

---

## ğŸ“‹ è®ºæ–‡ç´¢å¼•

| # | è®ºæ–‡ | ä¼šè®®/æœŸåˆŠ | å¹´ä»½ | æ ¸å¿ƒè´¡çŒ® | é‡è¦æ€§ |
|---|------|-----------|------|----------|--------|
| 1 | [Perceiver-Prompt: Flexible Speaker Adaptation](#1-perceiver-prompt) | Interspeech | 2024 | å¯å­¦ä¹ è¯´è¯äººPrompt | â­â­â­â­â­ |
| 2 | [On-the-fly MoE Routing](#2-moe-routing) | Interspeech | 2025 | ä¸¥é‡åº¦è‡ªåŠ¨è·¯ç”± | â­â­â­â­â­ |
| 3 | [Two-step Acoustic Model Adaptation](#3-two-step-adaptation) | ICASSP | 2020 | ä¸¤é˜¶æ®µLoRAå¾®è°ƒ | â­â­â­â­â­ |
| 4 | [Prototype-Based Adaptation](#4-prototype-adaptation) | Interspeech | 2024 | å†»ç»“è§£ç å™¨ç­–ç•¥ | â­â­â­â­ |
| 5 | [Dysarthric Speech Conformer](#5-conformer-adaptation) | ICASSP | 2025 | Conformeré€‚é… | â­â­â­â­ |
| 6 | [Householder Transformation Adapter](#6-householder-adapter) | Interspeech | 2023 | æè‡´å‚æ•°å‹ç¼© | â­â­â­ |
| 7 | [Curriculum Learning + Articulatory](#7-curriculum-learning) | Interspeech | 2024 | è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ | â­â­â­â­ |
| 8 | [Cross-Etiology Speaker-Independent](#8-cross-etiology) | ICASSP | 2025 | è·¨ç—…å› æ³›åŒ– | â­â­â­â­ |
| 9 | [Raw Waveform with PCNN](#9-raw-waveform-pcnn) | Interspeech | 2023 | åŒæµç‰¹å¾èåˆ | â­â­â­ |
| 10 | [Wav2vec2 Speaker Adaptation](#10-wav2vec2-adaptation) | Interspeech | 2022 | Adapteræ›¿ä»£æ–¹æ¡ˆ | â­â­â­ |

---

## ğŸ“– è®ºæ–‡è¯¦è§£

### 1. Perceiver-Prompt: Flexible Speaker Adaptation in Whisper
**Interspeech 2024** | [è®ºæ–‡é“¾æ¥](https://www.isca-archive.org/interspeech_2024/jiang24b_interspeech.pdf)

#### æ ¸å¿ƒåˆ›æ–°
ç”¨å¯è®­ç»ƒçš„ **Perceiver** æ¨¡å—æŠŠå¯å˜é•¿åº¦è¾“å…¥è¯­éŸ³ç¼–ç æˆ**å›ºå®šé•¿åº¦çš„ Speaker Prompt**ï¼Œæ³¨å…¥åˆ° Whisper ä¸­å®ç°è¯´è¯äººé€‚é…ã€‚

#### æ¶æ„å›¾
```
è¾“å…¥è¯­éŸ³ â†’ Whisper Encoder â†’ Perceiver (å¯å˜â†’å›ºå®š) â†’ Speaker Prompt
                                                          â†“
                               Whisper Decoder â† æ‹¼æ¥ â† Encoderè¾“å‡º
```

#### å…³é”®ç»“æœ
- åœ¨ä¸­æ–‡æ„éŸ³éšœç¢æ•°æ®ä¸Š CER ç›¸å¯¹é™ä½ **13.04%**
- Prompté•¿åº¦: 32~64 tokens æ•ˆæœæœ€ä½³

#### ç§»æ¤æ–¹æ¡ˆ
```python
# åœ¨Paraformerä¸­å®ç°Perceiver-Prompt
import torch.nn as nn

class PerceiverPrompt(nn.Module):
    def __init__(self, d_model=512, num_latents=32):
        super().__init__()
        # å¯å­¦ä¹ çš„æŸ¥è¯¢å‘é‡
        self.latent_queries = nn.Parameter(torch.randn(1, num_latents, d_model))
        # Cross-attention: ä»éŸ³é¢‘ç‰¹å¾æå–è¯´è¯äººä¿¡æ¯
        self.cross_attn = nn.MultiheadAttention(d_model, num_heads=8)
        
    def forward(self, audio_features):
        # audio_features: (B, T, D) å¯å˜é•¿åº¦
        B = audio_features.size(0)
        queries = self.latent_queries.expand(B, -1, -1)
        
        # è¾“å‡ºå›ºå®šé•¿åº¦çš„speaker prompt
        speaker_prompt, _ = self.cross_attn(
            queries.transpose(0, 1),
            audio_features.transpose(0, 1),
            audio_features.transpose(0, 1)
        )
        return speaker_prompt.transpose(0, 1)  # (B, num_latents, D)
```

#### å®éªŒè®¡åˆ’
- [ ] EXP-101: Perceiver-Promptåœ¨Paraformerä¸­çš„å®ç°
- [ ] EXP-102: Prompté•¿åº¦æ¶ˆèå®éªŒ (16/32/64/128)

---

### 2. On-the-fly MoE Routing for Dysarthric ASR
**Interspeech 2025** | [è®ºæ–‡é“¾æ¥](https://arxiv.org/pdf/2412.18832)

#### æ ¸å¿ƒæ€æƒ³
> ä¸åŒä¸¥é‡ç¨‹åº¦çš„æ„éŸ³éšœç¢éœ€è¦ä¸åŒçš„æ¨¡å‹å‚æ•° â†’ **MoE (Mixture of Experts) è·¯ç”±**

#### æ¶æ„
```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Router MLP  â”‚ â† è¾“å…¥éŸ³é¢‘ç‰¹å¾
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ æƒé‡åˆ†é…
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â†“              â†“              â†“
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ LoRA-è½» â”‚    â”‚ LoRA-ä¸­ â”‚    â”‚ LoRA-é‡ â”‚
      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
                    åŠ æƒèåˆè¾“å‡º
```

#### å®ç°æ­¥éª¤
1. æŒ‰ä¸¥é‡åº¦åˆ†åˆ«è®­ç»ƒ 3~5 ä¸ª LoRA
2. è®­ç»ƒä¸€ä¸ªå°å‹ Router ç½‘ç»œï¼ˆå‡ å±‚MLPï¼‰
3. Router æ ¹æ®è¾“å…¥è‡ªåŠ¨åˆ†é… LoRA æƒé‡

#### ç§»æ¤æ–¹æ¡ˆ
```python
class MoELoRARouter(nn.Module):
    def __init__(self, d_model=512, num_experts=3):
        super().__init__()
        self.router = nn.Sequential(
            nn.Linear(d_model, 128),
            nn.ReLU(),
            nn.Linear(128, num_experts),
            nn.Softmax(dim=-1)
        )
        
    def forward(self, audio_features):
        # å…¨å±€å¹³å‡æ± åŒ–
        pooled = audio_features.mean(dim=1)  # (B, D)
        weights = self.router(pooled)  # (B, num_experts)
        return weights

# ä½¿ç”¨æ—¶
router_weights = router(audio_features)  # [0.7, 0.2, 0.1]
output = sum(w * lora_i(x) for w, lora_i in zip(router_weights, loras))
```

#### å®éªŒè®¡åˆ’
- [ ] EXP-103: æŒ‰ä¸¥é‡åº¦åˆ†ç»„è®­ç»ƒå¤šä¸ªLoRA
- [ ] EXP-104: Routerç½‘ç»œæ¶æ„æ¢ç´¢
- [ ] EXP-105: MoE vs å•ä¸€LoRAå¯¹æ¯”

---

### 3. Two-step Acoustic Model Adaptation
**ICASSP 2020** | [è®ºæ–‡é“¾æ¥](https://ieeexplore.ieee.org/abstract/document/9053735)

#### æ ¸å¿ƒç­–ç•¥
> **é€šç”¨ç—…ç†é€‚é… â†’ ä¸ªäººå®šåˆ¶å¾®è°ƒ** åŒé˜¶æ®µLoRA

#### ä¸¤é˜¶æ®µæµç¨‹
```
Stage 1: é€šç”¨æ„éŸ³éšœç¢é€‚é…
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ•°æ®: æ‰€æœ‰æ‚£è€…çš„æ··åˆæ•°æ®                   â”‚
â”‚ ç›®æ ‡: å­¦ä¹ æ„éŸ³éšœç¢çš„é€šç”¨ç‰¹å¾               â”‚
â”‚ è¾“å‡º: Base-LoRA (é€šç”¨ç—…ç†)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
Stage 2: ä¸ªäººå®šåˆ¶å¾®è°ƒ  
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ•°æ®: ç‰¹å®šæ‚£è€…çš„15-20å¥è¯­éŸ³               â”‚
â”‚ ç›®æ ‡: é€‚é…ä¸ªä½“å‘éŸ³ç‰¹ç‚¹                    â”‚
â”‚ è¾“å‡º: User-LoRA (ä¸ªäººå®šåˆ¶)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
æ¨ç†: åŸºç¡€æ¨¡å‹ + Base-LoRA + User-LoRA
```

#### å®ç°ä»£ç 
```python
from peft import LoraConfig, get_peft_model

# Stage 1: é€šç”¨ç—…ç†LoRA
base_lora_config = LoraConfig(
    r=16,
    lora_alpha=32,
    target_modules=["encoder.layers.*.self_attn.q_proj", "encoder.layers.*.self_attn.v_proj"],
    lora_dropout=0.1,
)

# Stage 2: ä¸ªäººå®šåˆ¶LoRA (åœ¨Base-LoRAåŸºç¡€ä¸Š)
user_lora_config = LoraConfig(
    r=8,  # æ›´å°çš„rankï¼Œé¿å…è¿‡æ‹Ÿåˆ
    lora_alpha=16,
    target_modules=["encoder.layers.*.self_attn.q_proj"],
    lora_dropout=0.05,
)
```

#### å®éªŒè®¡åˆ’
- [ ] EXP-106: ä¸¤é˜¶æ®µLoRA vs å•é˜¶æ®µLoRA
- [ ] EXP-107: ä¸ªäººå®šåˆ¶æœ€å°‘æ•°æ®é‡æ¢ç´¢ (5/10/15/20å¥)

---

### 4. Prototype-Based Adaptation for Unseen Speakers
**Interspeech 2024** | [è®ºæ–‡é“¾æ¥](https://arxiv.org/abs/2407.18461)

#### æ ¸å¿ƒç­–ç•¥
> **å†»ç»“è§£ç å™¨ï¼Œä»…å¾®è°ƒç¼–ç å™¨** â†’ ä¿ç•™è¯­è¨€å»ºæ¨¡èƒ½åŠ›

#### å®éªŒå‘ç°
| å¾®è°ƒç­–ç•¥ | CER | åˆ†æ |
|----------|-----|------|
| å…¨å‚æ•°å¾®è°ƒ | è¾ƒå·® | é—å¿˜è¯­è¨€çŸ¥è¯† |
| å†»ç»“ç¼–ç å™¨ | è¾ƒå·® | å£°å­¦é€‚é…ä¸è¶³ |
| **å†»ç»“è§£ç å™¨** | **æœ€ä½³** | å¹³è¡¡å£°å­¦å’Œè¯­è¨€ |

#### ç§»æ¤å»ºè®®
```python
# Paraformerå¾®è°ƒæ—¶å†»ç»“è§£ç å™¨
for name, param in model.named_parameters():
    if "decoder" in name:
        param.requires_grad = False
    elif "encoder" in name:
        param.requires_grad = True
```

---

### 5. Dysarthric Speech Conformer Adaptation
**ICASSP 2025** | [è®ºæ–‡é“¾æ¥](https://ieeexplore.ieee.org/document/10889046)

#### å…³é”®é…ç½®
- **æŸå¤±å‡½æ•°**: 70% KLæ•£åº¦ + 30% CTC
- **æ•°æ®å¢å¼º**: SpecAugment + æ—¶é¢‘æ‰°åŠ¨ + è¯­é€Ÿå˜åŒ–
- **å†»ç»“ç­–ç•¥**: å†»ç»“Decoderï¼Œå¾®è°ƒEncoder

#### æ•°æ®å¢å¼ºé…ç½®
```python
augment_config = {
    "spec_augment": {
        "time_mask_max": 80,
        "freq_mask_max": 40,
        "n_time_masks": 2,
        "n_freq_masks": 2,
    },
    "speed_perturb": [0.9, 1.0, 1.1],
    "pitch_shift": [-2, 0, 2],  # åŠéŸ³
}
```

---

### 6. Householder Transformation Adapter
**Interspeech 2023** | [è®ºæ–‡é“¾æ¥](https://arxiv.org/html/2306.07090v1)

#### æ ¸å¿ƒåˆ›æ–°
ç”¨**åå°„æ­£äº¤çŸ©é˜µ**ä»£æ›¿å…¨è¿æ¥å±‚ï¼Œæè‡´å‹ç¼©å‚æ•°é‡ã€‚

#### æ•°å­¦åŸç†
```
Householderå˜æ¢: H = I - 2vv^T / (v^T v)
å…¶ä¸­ v æ˜¯å¯å­¦ä¹ å‘é‡ï¼ŒH æ˜¯æ­£äº¤çŸ©é˜µ
å‚æ•°é‡: O(d) vs å…¨è¿æ¥ O(dÂ²)
```

#### é€‚ç”¨åœºæ™¯
- æè‡´è¾¹ç¼˜ç«¯éƒ¨ç½²ï¼ˆå•ç‰‡æœºã€è¶…ä½åŠŸè€—ï¼‰
- ä¸æ”¯æŒLoRAç®—å­åŠ é€Ÿçš„ç¡¬ä»¶
- å‚æ•°é¢„ç®—æåº¦å—é™

---

### 7. Curriculum Learning with Articulatory Features
**Interspeech 2024** | [è®ºæ–‡é“¾æ¥](https://www.isca-archive.org/interspeech_2024/hsieh24_interspeech.pdf)

#### è¯¾ç¨‹å­¦ä¹ ç­–ç•¥
```
é˜¶æ®µ1: å¥åº·è¯­éŸ³é¢„è®­ç»ƒ (æ˜“)
    â†“
é˜¶æ®µ2: è½»åº¦æ„éŸ³éšœç¢ (ä¸­)
    â†“
é˜¶æ®µ3: ä¸­åº¦æ„éŸ³éšœç¢ (éš¾)
    â†“
é˜¶æ®µ4: é‡åº¦æ„éŸ³éšœç¢ (æœ€éš¾) + ä¸ªæ€§åŒ–å¾®è°ƒ
```

#### ç¥ç»å…ƒå†»ç»“ç­–ç•¥
- é˜¶æ®µ2: å†»ç»“å‰6å±‚
- é˜¶æ®µ3: å†»ç»“å‰3å±‚
- é˜¶æ®µ4: å…¨éƒ¨è§£å†»

---

### 8. Cross-Etiology and Speaker-Independent Recognition
**ICASSP 2025** | [è®ºæ–‡é“¾æ¥](https://arxiv.org/html/2501.14994v1)

#### æ ¸å¿ƒé—®é¢˜
> æ¨¡å‹æ€»æ˜¯å€¾å‘äº**è®°ä½å…·ä½“çš„äºº**ï¼Œè€Œä¸æ˜¯å­¦ä¹ **é€šç”¨çš„ç—…ç†æ¨¡å¼**

#### è§£å†³æ–¹æ¡ˆ
1. **é—å¿˜åˆ†æ”¯**: æ˜¾å¼é—å¿˜è¯´è¯äººç‰¹å®šä¿¡æ¯
2. **è¯´è¯äººå¯¹æŠ—æŸå¤±**: è®©æ¨¡å‹æ— æ³•åŒºåˆ†è¯´è¯äºº

```python
# è¯´è¯äººå¯¹æŠ—è®­ç»ƒ
class SpeakerAdversarialLoss(nn.Module):
    def __init__(self, d_model, num_speakers):
        self.speaker_classifier = nn.Linear(d_model, num_speakers)
        self.gradient_reversal = GradientReversal()
        
    def forward(self, features, speaker_ids):
        reversed_features = self.gradient_reversal(features)
        speaker_logits = self.speaker_classifier(reversed_features)
        return F.cross_entropy(speaker_logits, speaker_ids)
```

---

### 9. Raw Waveform with Parametric CNNs (SincNet)
**Interspeech 2023** | [è®ºæ–‡é“¾æ¥](https://kclpure.kcl.ac.uk/ws/portalfiles/portal/176300344/INTERSPEECH_2022.pdf)

#### åŒæµæ¶æ„
```
Stream A (ä¼ ç»Ÿ): Fbank â†’ Paraformer Encoder â†’ ç‰¹å¾
Stream B (æ³¢å½¢): Raw Waveform â†’ SincNet â†’ Linear â†’ ç‰¹å¾
                              â†“
                          ç‰¹å¾æ‹¼æ¥
                              â†“
                          è”åˆé¢„æµ‹
```

#### æ ¸å¿ƒæ€æƒ³
SincNet æ˜¯ç”Ÿç‰©ä»¿ç”Ÿå¬è§‰å‰ç«¯ï¼Œèƒ½æ•æ‰è¢«ä¼ ç»ŸFbanké—æ¼çš„**ç—…ç†é«˜é¢‘ç»†èŠ‚**ã€‚

---

### 10. Wav2vec2 Speaker Adaptation
**Interspeech 2022** | [è®ºæ–‡é“¾æ¥](https://arxiv.org/pdf/2204.00770)

#### LoRA vs Adapter
| æ–¹æ³• | å‚æ•°é‡ | æ•ˆæœ | æ¨è |
|------|--------|------|------|
| Adapter | æ›´å¤š | ç¨å¥½ | æœ‰è¶³å¤Ÿæ•°æ®æ—¶ |
| **LoRA** | æ›´å°‘ | ç›¸å½“ | **æ•°æ®ç¨€ç¼ºæ—¶** |

---

## ğŸ§ª å®éªŒè®¡åˆ’æ€»è§ˆ

### EXP-1XX: ASRé€‚é…å®éªŒç³»åˆ—

| ID | å®éªŒåç§° | å‡è®¾ | ä¼˜å…ˆçº§ |
|----|----------|------|--------|
| EXP-101 | Perceiver-Promptå®ç° | Speaker Promptæå‡é€‚é…æ€§ | P1 |
| EXP-102 | Prompté•¿åº¦æ¶ˆè | 32-64æœ€ä½³ | P2 |
| EXP-103 | å¤šLoRAæŒ‰ä¸¥é‡åº¦è®­ç»ƒ | ä¸åŒä¸¥é‡åº¦éœ€è¦ä¸åŒå‚æ•° | P1 |
| EXP-104 | MoE Routerè®¾è®¡ | è‡ªåŠ¨è·¯ç”±ä¼˜äºå›ºå®šé€‰æ‹© | P1 |
| EXP-105 | MoE vs å•ä¸€LoRA | MoEæ›´é²æ£’ | P0 |
| EXP-106 | ä¸¤é˜¶æ®µLoRAç­–ç•¥ | ä¸¤é˜¶æ®µä¼˜äºå•é˜¶æ®µ | P0 |
| EXP-107 | ä¸ªæ€§åŒ–æœ€å°‘æ•°æ®é‡ | 15-20å¥è¶³å¤Ÿ | P1 |
| EXP-108 | å†»ç»“ç­–ç•¥å¯¹æ¯” | å†»ç»“Decoderæœ€ä¼˜ | P0 |
| EXP-109 | è¯¾ç¨‹å­¦ä¹ æµç¨‹ | æ¸è¿›è®­ç»ƒä¼˜äºç›´æ¥å¾®è°ƒ | P1 |
| EXP-110 | è¯´è¯äººå¯¹æŠ—è®­ç»ƒ | æå‡è·¨è¯´è¯äººæ³›åŒ– | P2 |

---

## ğŸ’¡ æ ¸å¿ƒç»“è®ºä¸å»ºè®®

### âœ… æœ€ä½³å®è·µè·¯çº¿
```
1. åŸºç¡€æ¨¡å‹: Paraformer-large (éè‡ªå›å½’ï¼Œé€Ÿåº¦å¿«)
2. å¾®è°ƒç­–ç•¥: å†»ç»“Decoder + LoRAå¾®è°ƒEncoder
3. ä¸ªæ€§åŒ–: ä¸¤é˜¶æ®µLoRA (é€šç”¨ç—…ç† â†’ ä¸ªäººå®šåˆ¶)
4. è¿›é˜¶: MoEè·¯ç”± (æŒ‰ä¸¥é‡åº¦è‡ªåŠ¨é€‰æ‹©ä¸“å®¶)
```

### ğŸ“Š ç­–ç•¥å¯¹æ¯”

| ç­–ç•¥ | æ•ˆæœ | å¤æ‚åº¦ | æ¨èåœºæ™¯ |
|------|------|--------|----------|
| å…¨å‚æ•°å¾®è°ƒ | â­â­ | ä½ | ä¸æ¨è |
| å†»ç»“Decoder + LoRA | â­â­â­â­ | ä¸­ | é€šç”¨åœºæ™¯ |
| ä¸¤é˜¶æ®µLoRA | â­â­â­â­â­ | ä¸­ | éœ€è¦ä¸ªæ€§åŒ– |
| MoEè·¯ç”± | â­â­â­â­â­ | é«˜ | å¤šè¯´è¯äºº |
| Perceiver-Prompt | â­â­â­â­ | é«˜ | ç ”ç©¶æ¢ç´¢ |

---

## ğŸ“š ç›¸å…³èµ„æº

- [PEFT (LoRA) åº“](https://github.com/huggingface/peft)
- [Paraformer å¾®è°ƒæ–‡æ¡£](https://github.com/modelscope/FunASR/blob/main/docs/tutorial/finetune.md)
- [Whisper å¾®è°ƒæŒ‡å—](https://huggingface.co/blog/fine-tune-whisper)
