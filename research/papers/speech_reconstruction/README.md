# ğŸ”Š è¯­éŸ³é‡å»º/TTS (Speech Reconstruction)

> æ„éŸ³éšœç¢è¯­éŸ³çš„é‡å»ºä¸è½¬æ¢ï¼šTTSå¢å¼ºã€Voice Conversionã€è¯­éŸ³æ¢å¤

---

## ğŸ“‹ è®ºæ–‡åˆ—è¡¨ï¼ˆæŒ‰æ—¶é—´å€’åº + é‡è¦æ€§ï¼‰

### ğŸ”¥ 2025å¹´ è®ºæ–‡

| # | è®ºæ–‡ | ä¼šè®® | é‡è¦æ€§ |
|---|------|------|--------|
| 1 | DiffDSR: Latent Diffusion for Dysarthric Speech Reconstruction | ICASSP 2025 | â­â­â­â­â­ |
| 2 | Cross-lingual VC for Inclusive ASR | Interspeech 2025 | â­â­â­â­ |
| 3 | Unsupervised Rhythm and Voice Conversion | Interspeech 2025 | â­â­â­â­ |
| 4 | F5-TTS Fairness and Bias Study | ICASSP 2025 | â­â­â­â­ |
| 5 | Phone-purity Guided Discrete Tokens for VC | ICASSP 2025 | â­â­â­ |

### ğŸ“š 2024å¹´ è®ºæ–‡

| # | è®ºæ–‡ | ä¼šè®® | é‡è¦æ€§ |
|---|------|------|--------|
| 6 | CoLM-DSR: Neural Codec Language Modeling | Interspeech 2024 | â­â­â­â­â­ |
| 7 | Zero-shot TTS for Atypical Speech | Interspeech 2024 | â­â­â­â­ |
| 8 | CosyVoice: Scalable Multi-lingual TTS | arXiv 2024 | â­â­â­â­â­ |

### ğŸ“– 2023å¹´åŠæ›´æ—© è®ºæ–‡

| # | è®ºæ–‡ | ä¼šè®® | é‡è¦æ€§ |
|---|------|------|--------|
| 9 | F5-TTS: Flow-based Zero-shot TTS | arXiv 2024 | â­â­â­â­â­ |
| 10 | Parrotron: End-to-End Speech Conversion | arXiv 2021 | â­â­â­â­â­ |
| 11 | VoiceLoop: Neural TTS for Speech Disorders | 2018 | â­â­â­ |
| 12 | Tacotron-based Dysarthric Speech Synthesis | 2019 | â­â­â­ |

---

## ğŸ“– æ ¸å¿ƒè®ºæ–‡è¯¦è§£

### 1. DiffDSR: Latent Diffusion for Dysarthric Speech Reconstruction â­â­â­â­â­
**ICASSP 2025** | [è®ºæ–‡](https://arxiv.org/abs/2501.xxxxx)

#### æ ¸å¿ƒåˆ›æ–°
> ä½¿ç”¨**æ½œåœ¨æ‰©æ•£æ¨¡å‹**å°†ç—…æ€è¯­éŸ³é‡å»ºä¸ºæ¸…æ™°è¯­éŸ³

#### æŠ€æœ¯æ¶æ„
```
ç—…æ€è¯­éŸ³ â†’ Encoder â†’ æ½œåœ¨ç©ºé—´ â†’ Diffusion â†’ æ¸…æ™°è¯­éŸ³
                         â†“
                    å™ªå£°è°ƒåº¦å™¨
                         â†“
                  ä¿ç•™è¯­ä¹‰ï¼Œä¿®å¤å‘éŸ³
```

#### å®ç°æ¡†æ¶
```python
import torch
import torch.nn as nn

class DiffDSR(nn.Module):
    """æ½œåœ¨æ‰©æ•£è¯­éŸ³é‡å»º"""
    def __init__(self, latent_dim=512, time_steps=1000):
        super().__init__()
        self.encoder = SpeechEncoder(out_dim=latent_dim)
        self.decoder = SpeechDecoder(in_dim=latent_dim)
        self.diffusion = GaussianDiffusion(
            denoise_fn=UNet1D(latent_dim),
            timesteps=time_steps
        )
        
    def forward(self, dysarthric_audio, target_audio=None):
        # ç¼–ç åˆ°æ½œåœ¨ç©ºé—´
        z_d = self.encoder(dysarthric_audio)
        
        if target_audio is not None:  # è®­ç»ƒæ¨¡å¼
            z_t = self.encoder(target_audio)
            loss = self.diffusion(z_d, z_t)
            return loss
        else:  # æ¨ç†æ¨¡å¼
            z_clean = self.diffusion.sample(z_d)
            return self.decoder(z_clean)
```

#### å…³é”®æŠ€æœ¯
- **å†…å®¹-éŸµå¾‹è§£è€¦**: ä¿ç•™è¯´è¯äººèº«ä»½
- **è¯­ä¹‰ä¿æŒçº¦æŸ**: ç¡®ä¿è½¬å½•ä¸€è‡´
- **æ¸è¿›å»å™ª**: 1000æ­¥æ‰©æ•£è¿‡ç¨‹

---

### 2. CoLM-DSR: Neural Codec Language Modeling â­â­â­â­â­
**Interspeech 2024** | [è®ºæ–‡](https://arxiv.org/abs/2406.xxxxx)

#### æ ¸å¿ƒåˆ›æ–°
> ä½¿ç”¨**ç¥ç»ç¼–è§£ç å™¨è¯­è¨€æ¨¡å‹**è¿›è¡Œè¯­éŸ³é‡å»º

#### æŠ€æœ¯æ–¹æ¡ˆ
```python
class CoLMDSR:
    """Codec Language Model for DSR"""
    def __init__(self):
        self.codec = EncodecModel.from_pretrained("facebook/encodec_24khz")
        self.lm = TransformerLM(vocab_size=1024, d_model=512)
        
    def encode(self, audio):
        """ç¼–ç ä¸ºç¦»æ•£tokens"""
        return self.codec.encode(audio)
        
    def reconstruct(self, dysarthric_tokens):
        """è‡ªå›å½’é‡å»ºæ¸…æ™°tokens"""
        clean_tokens = self.lm.generate(dysarthric_tokens)
        return self.codec.decode(clean_tokens)
```

#### ä¼˜åŠ¿
- åˆ©ç”¨å¤§è§„æ¨¡é¢„è®­ç»ƒç¼–è§£ç å™¨
- ç¦»æ•£tokenä¾¿äºè¯­è¨€æ¨¡å‹å»ºæ¨¡
- å¯èåˆæ–‡æœ¬å…ˆéªŒ

---

### 3. Parrotron: End-to-End Speech Conversion â­â­â­â­â­
**Google 2021** | [è®ºæ–‡](https://arxiv.org/abs/1904.04169)

#### æ ¸å¿ƒè®¾è®¡
> **ç«¯åˆ°ç«¯Seq2Seq**: ç—…æ€è¯­éŸ³ â†’ æ¸…æ™°è¯­éŸ³

#### æ¶æ„
```
Input: ç—…æ€è¯­éŸ³é¢‘è°±
   â†“
Encoder (Conformer)
   â†“
Attention
   â†“
Decoder (Autoregressive)
   â†“
Vocoder (HiFi-GAN)
   â†“
Output: æ¸…æ™°è¯­éŸ³æ³¢å½¢
```

#### è®­ç»ƒç­–ç•¥
```python
# å¤šä»»åŠ¡å­¦ä¹ 
losses = {
    "reconstruction": F.mse_loss(pred_mel, target_mel),
    "asr_ctc": ctc_loss(pred_text, target_text),
    "speaker_similarity": cosine_loss(spk_emb_pred, spk_emb_target)
}
total_loss = sum(losses.values())
```

---

### 4. F5-TTS: Flow-based Zero-shot TTS â­â­â­â­â­
**arXiv 2024** | [è®ºæ–‡](https://arxiv.org/abs/2410.06885)

#### æ ¸å¿ƒä¼˜åŠ¿
> **æ— éœ€fine-tuneå³å¯å…‹éš†å£°éŸ³**

#### åº”ç”¨äºæ„éŸ³éšœç¢
```python
class F5TTSDysarthricAugmentation:
    """ä½¿ç”¨F5-TTSç”Ÿæˆç—…æ€è¯­éŸ³"""
    def __init__(self):
        self.f5tts = F5TTS.from_pretrained("...")
        
    def augment(self, text, healthy_audio, style="dysarthric"):
        """ç”Ÿæˆå¸¦æ„éŸ³éšœç¢é£æ ¼çš„è¯­éŸ³"""
        # æ–¹æ¡ˆ1: ç”¨å¥åº·å‚è€ƒç”Ÿæˆï¼Œå†åŠ ç—…æ€æ‰°åŠ¨
        clean_audio = self.f5tts.synthesize(text, ref=healthy_audio)
        return self.add_dysarthric_style(clean_audio, style)
        
    def add_dysarthric_style(self, audio, style):
        """æ·»åŠ ç—…æ€ç‰¹å¾"""
        if style == "slow":
            return librosa.effects.time_stretch(audio, rate=0.7)
        elif style == "breathy":
            return self.add_breathiness(audio)
        elif style == "slurred":
            return self.add_formant_shift(audio)
```

#### å…¬å¹³æ€§ç ”ç©¶å‘ç°
- åŸå§‹F5-TTSå¯¹éå…¸å‹è¯­éŸ³å­˜åœ¨**åè§**
- éœ€è¦é’ˆå¯¹æ€§æ•°æ®å¢å¼ºæ”¹å–„

---

### 5. CosyVoice: Scalable Multi-lingual TTS â­â­â­â­â­
**é˜¿é‡Œå·´å·´ 2024** | [è®ºæ–‡](https://arxiv.org/abs/2407.xxxxx)

#### æ ¸å¿ƒèƒ½åŠ›
- **é›¶æ ·æœ¬å£°éŸ³å…‹éš†**
- **è·¨è¯­è¨€åˆæˆ**
- **æƒ…æ„Ÿæ§åˆ¶**

#### æ„éŸ³éšœç¢åº”ç”¨
```python
from cosyvoice import CosyVoice

class CosyVoiceAugmenter:
    """CosyVoiceæ•°æ®å¢å¼º"""
    def __init__(self):
        self.model = CosyVoice.from_pretrained("CosyVoice-300M")
        
    def generate_dysarthric_parallel(self, text, patient_audio, healthy_audio):
        """ç”Ÿæˆé…å¯¹æ•°æ®"""
        # æå–æ‚£è€…å£°éŸ³ç‰¹å¾
        patient_spk = self.model.extract_speaker(patient_audio)
        
        # ç”¨å¥åº·äººå‘éŸ³é£æ ¼ + æ‚£è€…å£°éŸ³ = ç†æƒ³ç›®æ ‡
        # è¿™æ ·å¯ä»¥ç”Ÿæˆ (patient_dysarthric, patient_ideal) é…å¯¹
        ideal = self.model.synthesize(
            text=text,
            speaker=patient_spk,
            style="clear"  # æ¸…æ™°å‘éŸ³é£æ ¼
        )
        return ideal
```

---

### 6. Cross-lingual VC for Inclusive ASR â­â­â­â­
**Interspeech 2025** | [è®ºæ–‡](https://arxiv.org/abs/2505.14874)

#### æ ¸å¿ƒæ€æƒ³
> è·¨è¯­è¨€è¿ç§»ç—…æ€ç‰¹å¾ï¼Œæ‰©å……ä½èµ„æºè¯­è¨€æ•°æ®

#### æŠ€æœ¯æµç¨‹
```
è‹±è¯­ç—…æ€è¯­éŸ³ â†’ ç‰¹å¾æå– â†’ ç—…æ€é£æ ¼ç¼–ç 
                              â†“
ä¸­æ–‡å¥åº·è¯­éŸ³ â†’ å†…å®¹æå– â†’ + ç—…æ€é£æ ¼ â†’ ä¸­æ–‡ç—…æ€è¯­éŸ³
```

---

### 7. Unsupervised Rhythm and Voice Conversion â­â­â­â­
**Interspeech 2025** | [è®ºæ–‡](https://arxiv.org/abs/2506.01618)

#### æ ¸å¿ƒè´¡çŒ®
> **æ— ç›‘ç£å­¦ä¹ éŸµå¾‹è½¬æ¢**

#### åº”ç”¨åœºæ™¯
- å°†æ­£å¸¸è¯­é€Ÿæ˜ å°„åˆ°ç—…æ€è¯­é€Ÿï¼ˆæ•°æ®å¢å¼ºï¼‰
- å°†ç—…æ€è¯­é€Ÿè§„æ•´ä¸ºæ­£å¸¸è¯­é€Ÿï¼ˆé¢„å¤„ç†ï¼‰

---

## ğŸ”¬ å®éªŒè®¡åˆ’

| å®éªŒID | æè¿° | ä¼˜å…ˆçº§ | æ¨¡å‹ | é¢„æœŸæ”¶ç›Š |
|--------|------|--------|------|----------|
| EXP-401 | F5-TTSé›¶æ ·æœ¬å…‹éš† + ç—…æ€æ‰°åŠ¨ | P0 | F5-TTS | 10å€æ•°æ® |
| EXP-402 | CosyVoiceç”Ÿæˆç†æƒ³é…å¯¹ | P0 | CosyVoice | é…å¯¹æ•°æ® |
| EXP-403 | DiffDSRè¯­éŸ³é‡å»º | P1 | Diffusion | æ¸…æ™°åŒ– |
| EXP-404 | Parrotronç«¯åˆ°ç«¯è½¬æ¢ | P1 | Seq2Seq | å®æ—¶è½¬æ¢ |
| EXP-405 | CoLMç¦»æ•£tokenå»ºæ¨¡ | P2 | Codec LM | æ–°èŒƒå¼ |
| EXP-406 | è·¨è¯­è¨€ç—…æ€è¿ç§» | P2 | VC | æ•°æ®æ‰©å…… |

---

## âœ… æ¨èæŠ€æœ¯è·¯çº¿

### æ•°æ®å¢å¼ºè·¯çº¿
```
å¥åº·è¯­éŸ³è¯­æ–™ (AISHELL/WenetSpeech)
         â†“
    F5-TTS / CosyVoice
         â†“
    é›¶æ ·æœ¬å£°éŸ³å…‹éš†
         â†“
    æ·»åŠ ç—…æ€ç‰¹å¾æ‰°åŠ¨
         â†“
    å¤§è§„æ¨¡ä¼ªç—…æ€è¯­éŸ³
```

### è¯­éŸ³é‡å»ºè·¯çº¿
```
ç—…æ€è¯­éŸ³è¾“å…¥
     â†“
DiffDSR / Parrotron
     â†“
æ¸…æ™°è¯­éŸ³è¾“å‡º
     â†“
ASRè¯†åˆ«
```

### é…å¯¹æ•°æ®ç”Ÿæˆ
```
æ‚£è€…è¯­éŸ³ + æ–‡æœ¬æ ‡æ³¨
         â†“
CosyVoice (æ‚£è€…å£°éŸ³ + æ¸…æ™°é£æ ¼)
         â†“
(ç—…æ€,ç†æƒ³) é…å¯¹æ•°æ®
         â†“
è®­ç»ƒè¯­éŸ³é‡å»ºæ¨¡å‹
```

---

## ğŸ“Š TTS/VCæ¨¡å‹å¯¹æ¯”

| æ¨¡å‹ | ç±»å‹ | é›¶æ ·æœ¬ | ä¸­æ–‡æ”¯æŒ | å¼€æº | æ¨èåº¦ |
|------|------|--------|----------|------|--------|
| F5-TTS | Flow | âœ… | âœ… | âœ… | â­â­â­â­â­ |
| CosyVoice | AR+NAR | âœ… | âœ… | âœ… | â­â­â­â­â­ |
| VALL-E | AR | âœ… | âŒ | âŒ | â­â­â­ |
| XTTS | AR | âœ… | âœ… | âœ… | â­â­â­â­ |
| Parrotron | Seq2Seq | âŒ | âŒ | âŒ | â­â­â­ |

---

## ğŸ¯ å…³é”®ä»£ç ç‰‡æ®µ

### ç—…æ€ç‰¹å¾æ³¨å…¥
```python
import librosa
import numpy as np

def inject_dysarthric_features(audio, sr=16000, severity="mild"):
    """å‘å¥åº·è¯­éŸ³æ³¨å…¥æ„éŸ³éšœç¢ç‰¹å¾"""
    params = {
        "mild": {"speed": 0.9, "jitter": 0.02, "breathiness": 0.1},
        "moderate": {"speed": 0.75, "jitter": 0.05, "breathiness": 0.2},
        "severe": {"speed": 0.6, "jitter": 0.1, "breathiness": 0.3},
    }[severity]
    
    # 1. è¯­é€Ÿå˜æ…¢
    audio = librosa.effects.time_stretch(audio, rate=params["speed"])
    
    # 2. æ·»åŠ é¢¤æŠ– (jitter)
    jitter = np.random.randn(len(audio)) * params["jitter"]
    audio = audio + jitter
    
    # 3. æ·»åŠ æ°”æ¯éŸ³
    noise = np.random.randn(len(audio)) * params["breathiness"]
    audio = audio + noise * 0.1
    
    return audio

def add_stutter(audio, sr=16000, repeat_prob=0.1):
    """æ·»åŠ ç»“å·´/é‡å¤"""
    # éšæœºé€‰æ‹©éŸ³èŠ‚é‡å¤
    chunks = librosa.effects.split(audio, top_db=20)
    result = []
    for start, end in chunks:
        chunk = audio[start:end]
        if np.random.rand() < repeat_prob:
            result.extend([chunk] * np.random.randint(2, 4))
        else:
            result.append(chunk)
    return np.concatenate(result)
```

---

## ğŸ“š ç›¸å…³èµ„æº

- [F5-TTS å®˜æ–¹ä»“åº“](https://github.com/SWivid/F5-TTS)
- [CosyVoice å®˜æ–¹ä»“åº“](https://github.com/FunAudioLLM/CosyVoice)
- [Parrotron è®ºæ–‡](https://arxiv.org/abs/1904.04169)
