# 🔬 构音障碍ASR实验设计文档

> **项目**: CLEAR-VOX (Chinese Low-resource Dysarthria ASR)  
> **日期**: 2025-12-24  
> **版本**: v1.0  
> **作者**: CLEAR-VOX Team

---

## 📋 目录

1. [研究背景与目标](#1-研究背景与目标)
2. [数据集概述](#2-数据集概述)
3. [实验设计](#3-实验设计)
4. [评估指标](#4-评估指标)
5. [实验记录表](#5-实验记录表)
6. [预期结果与分析](#6-预期结果与分析)
7. [风险与缓解措施](#7-风险与缓解措施)
8. [参考文献](#8-参考文献)

---

## 1. 研究背景与目标

### 1.1 研究背景

构音障碍(Dysarthria)是一种运动性言语障碍，由神经肌肉损伤导致言语清晰度下降。现有ASR系统对构音障碍语音的识别效果显著差于正常语音，主要原因包括：

- **发音不清晰**: 辅音/元音替换、省略、扭曲
- **语速异常**: 过慢或过快，节奏不规律
- **韵律异常**: 音调变化异常，重音位置错误
- **数据稀缺**: 标注数据获取困难，属于低资源场景

### 1.2 研究目标

| 目标 | 具体指标 | 优先级 |
|------|----------|--------|
| **主目标** | CER < 20% (优于人类基线20.45%) | P0 |
| **次目标** | CER < 16.4% (达到CDSD SOTA) | P1 |
| **泛化目标** | 未见说话人CER < 25% | P2 |

### 1.3 技术方案

采用 **FunASR Paraformer-large** 模型进行微调：
- 模型: iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch
- 参数量: 220M
- 预训练数据: 60,000小时中文语音
- 架构优势: 非自回归(NAR)，推理速度快10倍

---

## 2. 数据集概述

### 2.1 数据来源

| 数据集 | 来源 | 时长 | 说话人数 | 样本数 | 说明 |
|--------|------|------|----------|--------|------|
| **1h Dataset** | CDSD子集 | ~1小时 | 44人 | 56,166 | 多说话人，少样本 |
| **10h Dataset** | CDSD子集 | ~10小时 | 8人 | 92,799 | 少说话人，多样本 |
| **合并数据集** | 1h + 10h | ~11小时 | 44人* | 148,965* | 去重后 |

> *注：8位说话人在两个数据集中重叠，需要去重处理

### 2.2 说话人分布详情

#### 10h 数据集说话人 (8人, 92,799样本)

| 说话人ID | 样本数 | 占比 | 在1h数据集中 |
|----------|--------|------|--------------|
| 01 | 12,734 | 13.7% | ✅ 1,112样本 |
| 02 | 5,772 | 6.2% | ✅ 999样本 |
| 04 | 11,381 | 12.3% | ✅ 1,035样本 |
| 06 | 10,309 | 11.1% | ✅ 969样本 |
| 08 | 14,470 | 15.6% | ✅ 999样本 |
| 09 | 14,490 | 15.6% | ✅ 1,156样本 |
| 12 | 15,566 | 16.8% | ✅ 1,155样本 |
| 20 | 8,077 | 8.7% | ✅ 936样本 |
| **合计** | **92,799** | 100% | 8,361样本 |

#### 1h 数据集说话人 (44人, 56,166样本)

- **重叠说话人 (8人)**: 01, 02, 04, 06, 08, 09, 12, 20 — 共8,361样本
- **独有说话人 (36人)**: 03, 05, 07, 10, 11, 13-19, 21-44 — 共47,805样本
- **平均每人样本数**: ~1,277样本/人

### 2.3 数据去重策略

由于8位说话人在两个数据集中重叠，合并时需要去重：

- 去重策略1: 使用 utterance_id 去重（推荐）
- 去重策略2: 保留10h数据集版本（样本更多）
- 验证去重后数据完整性

去重后预估：
- 10h完整数据: 92,799 样本
- 1h独有数据: 47,805 样本 (36人)
- 合并后总计: ~140,604 样本

---

## 3. 实验设计

### 3.1 实验总览

```
Phase 1: 基线建立
├── EXP-001: Baseline (原始模型)
└── EXP-002: 1h微调 (已有)

Phase 2: 数据规模实验
├── EXP-003: 10h微调
└── EXP-004: 11h联合微调 (1h+10h)

Phase 3: 说话人泛化实验
├── EXP-005: 跨说话人测试
└── EXP-006: 少样本适应

Phase 4: 消融实验
├── EXP-007: 数据增强对比
└── EXP-008: 学习率/Epoch调优
```

### 3.2 Phase 1: 基线建立

#### EXP-001: 基线测试 (Baseline)

| 属性 | 值 |
|------|-----|
| **目标** | 评估原始Paraformer在构音障碍数据上的表现 |
| **模型** | Paraformer-large (原始) |
| **测试集** | 1h test set (5人, 6,064样本) |
| **预期CER** | 25-35% |

执行命令:
```bash
python scripts/inference_finetuned.py \
  --model "iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch" \
  --test data/1h_dataset/test.jsonl \
  --output exp/baseline_results.json
```

#### EXP-002: 1h数据微调

| 属性 | 值 |
|------|-----|
| **目标** | 使用1h数据微调Paraformer |
| **训练集** | 1h train (35人, ~45,000样本) |
| **验证集** | 1h val (4人, ~4,500样本) |
| **测试集** | 1h test (5人, ~6,000样本) |
| **配置** | batch=6000, lr=0.0002, epoch=50 |
| **预期CER** | 16-22% |
| **状态** | ⏳ 已部分训练 (epoch 4中断) |

### 3.3 Phase 2: 数据规模实验

#### EXP-003: 10h数据微调

| 属性 | 值 |
|------|-----|
| **目标** | 探索更多数据对ASR性能的影响 |
| **训练集** | 10h全量 (8人, ~83,000样本) - 90%划分 |
| **验证集** | 10h验证 (8人, ~4,600样本) - 5%划分 |
| **测试集** | 10h测试 (8人, ~4,600样本) - 5%划分 |
| **配置** | batch=6000, lr=0.0002, epoch=30 |
| **预期CER** | 14-18% |

#### EXP-004: 11h联合微调 (1h + 10h)

| 属性 | 值 |
|------|-----|
| **目标** | 探索数据合并对性能的影响 |
| **训练方式** | 合并1h训练集 + 10h训练集 |
| **测试集** | 多个测试集交叉验证 |
| **关注点** | 1. 总体CER提升 2. 多说话人泛化 |

### 3.4 Phase 3: 说话人泛化实验

#### EXP-005: 跨说话人测试

| 属性 | 值 |
|------|-----|
| **目标** | 评估模型对未见说话人的泛化能力 |
| **训练集** | 38位说话人训练 |
| **测试集** | 6位完全未见说话人测试 |
| **关注指标** | 见过vs未见说话人CER差距 |

#### EXP-006: 少样本说话人适应

| 属性 | 值 |
|------|-----|
| **目标** | 评估少量数据快速适应新说话人的能力 |
| **方法** | 基于EXP-004模型，使用少量新说话人数据微调 |
| **样本量** | 100/500/1000条 |
| **微调策略** | LoRA (可选) / 全量微调 |

### 3.5 Phase 4: 消融实验

#### EXP-007: 数据增强对比

| 增强方法 | 说明 | 预期效果 |
|----------|------|----------|
| **None** | 基线，无增强 | CER基准 |
| **SpecAugment** | 时频遮盖 | +0-2%提升 |
| **Speed Perturbation** | 语速变化0.9x-1.1x | +1-3%提升 |
| **Noise Injection** | 加噪训练 | +0-1%提升 |
| **组合** | 上述组合 | +2-4%提升 |

#### EXP-008: 超参数调优

| 参数 | 值范围 | 最佳选择依据 |
|------|--------|--------------|
| Learning Rate | 1e-4, 2e-4, 5e-4 | 验证集CER |
| Batch Size | 4000, 6000, 8000 | 显存限制+收敛速度 |
| Max Epoch | 30, 50, 100 | 验证集Early Stop |
| Warmup Steps | 0, 500, 1000 | 训练稳定性 |

---

## 4. 评估指标

### 4.1 主要指标

| 指标 | 计算方式 | 目标值 |
|------|----------|--------|
| **CER (字符错误率)** | (S+D+I)/N × 100% | < 20% |
| **WER (词错误率)** | 同上，以词为单位 | 参考 |
| **SER (句子错误率)** | 有错句子/总句子 | 参考 |

### 4.2 分析指标

| 指标 | 说明 | 用途 |
|------|------|------|
| **Per-Speaker CER** | 每位说话人单独CER | 泛化分析 |
| **CER by Severity** | 按障碍程度分层CER | 难度分析 |
| **Insertion/Deletion/Substitution** | 错误类型分布 | 错误分析 |
| **Inference Time** | 推理延迟 | 实用性评估 |
| **RTF (实时因子)** | 推理时间/音频时长 | 实时性评估 |

---

## 5. 实验记录表

### 5.1 实验进度总览

| 实验ID | 实验名称 | 状态 | 开始日期 | 完成日期 | 负责人 |
|--------|----------|------|----------|----------|--------|
| EXP-001 | Baseline | ⬜ 待执行 | - | - | - |
| EXP-002 | 1h微调 | 🔄 进行中 | 2025-12-23 | - | - |
| EXP-003 | 10h微调 | ⬜ 待执行 | - | - | - |
| EXP-004 | 11h联合 | ⬜ 待执行 | - | - | - |
| EXP-005 | 跨说话人 | ⬜ 待执行 | - | - | - |
| EXP-006 | 少样本适应 | ⬜ 待执行 | - | - | - |
| EXP-007 | 数据增强 | ⬜ 待执行 | - | - | - |
| EXP-008 | 超参调优 | ⬜ 待执行 | - | - | - |

### 5.2 详细结果记录

#### EXP-001: Baseline
- 测试集: 1h test (5人, 6,064样本)
- 总体CER: 82.07%
- 推理时间: 待测
- GPU显存: 待测

#### EXP-002: 1h微调
- 训练集: 35人, ~45,000样本
- 验证集: 4人, ~4,500样本  
- 测试集: 5人, ~6,000样本
- 最佳Epoch: 待训练
- 验证CER: 待训练
- 测试CER: 待训练
- 训练时长: ~4小时 (epoch 4中断，磁盘问题已修复)

---

## 6. 预期结果与分析

### 6.1 CER预期对比

```
CER%
 40 |
 35 |████████ EXP-001 Baseline (预估30%)
 30 |████████
 25 |████████
 20 |-------- 人类基线 (20.45%) --------
 18 |        ████████ EXP-002 1h微调 (预估18%)
 16 |                ████████ EXP-003 10h微调 (预估16%)
 14 |                        ████████ EXP-004 11h联合 (预估14%)
 12 |
 10 |-----------------------------------------
     Base  1h微调 10h微调 11h联合  CDSD-SOTA(16.4%)
```

### 6.2 关键假设

1. **数据规模假设**: 更多数据(10h > 1h)会带来更好的性能
2. **说话人多样性假设**: 更多说话人(44人 > 8人)有助于泛化
3. **联合训练假设**: 合并数据集能结合两者优势

---

## 7. 风险与缓解措施

### 7.1 技术风险

| 风险 | 可能性 | 影响 | 缓解措施 |
|------|--------|------|----------|
| 训练不收敛 | 中 | 高 | 监控loss，调整lr |
| 过拟合 | 高 | 中 | Early stop, 正则化 |
| 显存不足 | 低 | 中 | 降低batch_size |
| 磁盘空间 | 中 | 高 | 使用autodl-tmp, 定期清理 |

### 7.2 数据风险

| 风险 | 可能性 | 影响 | 缓解措施 |
|------|--------|------|----------|
| 数据泄露 | 中 | 高 | 严格划分train/val/test |
| 标签噪声 | 中 | 中 | 数据清洗，人工校验 |
| 分布偏移 | 中 | 中 | 交叉验证，多测试集 |

---

## 8. 参考文献

### 8.1 数据集

**CDSD: Chinese Dysarthria Speech Database**  
- 会议: INTERSPEECH 2024  
- 规模: 133小时，44位说话人  
- 最佳CER: 16.4% (Hybrid CTC/Attention)  
- 人类基线: 20.45%  
- arXiv: https://arxiv.org/abs/2310.15930

### 8.2 模型

**Paraformer: Fast and Accurate Parallel Transformer for Non-autoregressive End-to-End Speech Recognition**  
- 会议: INTERSPEECH 2022  
- arXiv: https://arxiv.org/abs/2206.08317

### 8.3 框架

**FunASR: A Fundamental End-to-End Speech Recognition Toolkit**  
- GitHub: https://github.com/modelscope/FunASR  
- 文档: https://funasr.readthedocs.io  
- ModelScope: https://modelscope.cn

---

## 📎 附录

### A. 文件路径

```
/root/autodl-tmp/
├── 1h/                     (原始数据)
│   ├── Audio/              (44个说话人目录)
│   └── Text/               (标签文件)
├── 10h/                    (原始数据)
│   ├── Audio/              (8个说话人目录)
│   └── Text/               (标签文件)
├── exp/                    (模型输出)
│   └── paraformer_finetune_1h_optimized/
└── modelscope_cache/       (模型缓存)

/root/CLEAR-VOX-MODEL/
├── data/
│   ├── 1h_dataset/
│   │   ├── train.jsonl
│   │   ├── val.jsonl
│   │   └── test.jsonl
│   └── 10h_dataset/        (待创建)
├── scripts/
│   ├── finetune_paraformer_optimized.sh
│   ├── inference_finetuned.py
│   └── prepare_10h_dataset.py  (待创建)
└── docs/
    ├── EXPERIMENT_DESIGN.md  (本文档)
    ├── EXPERIMENT_LOG.md
    ├── FINETUNE_MANUAL_v2.md
    └── TECHNICAL_ROADMAP.md
```

### B. 执行清单

- [ ] 准备10h数据集 (prepare_10h_dataset.py)
- [ ] 运行EXP-001基线测试
- [ ] 完成EXP-002训练 (从epoch 4继续)
- [ ] 准备11h联合数据集
- [ ] 设计说话人划分方案
- [ ] 实现数据增强脚本

---

**文档状态**: 📝 草稿  
**最后更新**: 2025-12-24  
**下次审核**: 完成Phase 1后

---

## 📊 实验结果更新 (2025-12-24)

### EXP-001: Baseline 结果

| 指标 | 值 | 说明 |
|------|-----|------|
| **模型** | Paraformer-large (原始预训练) | 无任何微调 |
| **测试集** | 1h test (5人, 6,064样本) | |
| **CER** | **82.07%** | 远高于预期 |
| **状态** | ✅ 已完成 | 2025-12-24 |

**分析**:
- 原始 Paraformer 模型（60,000小时正常语音预训练）在构音障碍语音上表现很差
- CER 82.07% 说明模型几乎无法正确识别构音障碍语音
- 这验证了构音障碍ASR的挑战性和微调的必要性
- 微调潜在提升空间: 82.07% → <20% (目标)

### EXP-002: 1h微调 (进行中)

| 指标 | 值 | 说明 |
|------|-----|------|
| **模型** | Paraformer-large + 1h微调 | |
| **训练数据** | 45,327 样本 (35人) | |
| **当前状态** | 🔄 训练中 | Epoch 3/50 |
| **测试CER** | 待训练完成 | |

---

---

## 📊 实验结果更新 (2025-12-24)

### EXP-001: Baseline 结果

| 指标 | 值 | 说明 |
|------|-----|------|
| **模型** | Paraformer-large (原始预训练) | 无任何微调 |
| **测试集** | 1h test (5人, 6,064样本) | |
| **CER** | **82.07%** | 远高于预期 |
| **状态** | ✅ 已完成 | 2025-12-24 |

**分析**:
- 原始 Paraformer 模型（60,000小时正常语音预训练）在构音障碍语音上表现很差
- CER 82.07% 说明模型几乎无法正确识别构音障碍语音
- 这验证了构音障碍ASR的挑战性和微调的必要性
- 微调潜在提升空间: 82.07% -> <20% (目标)

### EXP-002: 1h微调 (进行中)

| 指标 | 值 | 说明 |
|------|-----|------|
| **模型** | Paraformer-large + 1h微调 | |
| **训练数据** | 45,327 样本 (35人) | |
| **当前状态** | 训练中 | Epoch 3/50 |
| **测试CER** | 待训练完成 | |
