# ğŸ¯ FunASR æ„éŸ³éšœç¢è¯­éŸ³è¯†åˆ«å¾®è°ƒæ‰‹å†Œ v2.0

> **ç¡¬ä»¶**: RTX 3090 24GB | **æ¡†æ¶**: FunASR | **ç›®æ ‡**: ä¸­æ–‡æ„éŸ³éšœç¢ ASR
> 
> **æ›´æ–°**: åŸºäºå®˜æ–¹é…ç½®æ ¡éªŒ + CDSDè®ºæ–‡ (INTERSPEECH 2024) ä¼˜åŒ–

---

## ğŸ“‹ ç›®å½•
1. [æ¨¡å‹é€‰æ‹©](#1-æ¨¡å‹é€‰æ‹©)
2. [ç¯å¢ƒé…ç½®](#2-ç¯å¢ƒé…ç½®)
3. [æ•°æ®å‡†å¤‡](#3-æ•°æ®å‡†å¤‡)
4. [è®­ç»ƒé…ç½®](#4-è®­ç»ƒé…ç½®) âš ï¸ **å·²æ›´æ–°**
5. [æ‰§è¡Œè®­ç»ƒ](#5-æ‰§è¡Œè®­ç»ƒ)
6. [æ¨¡å‹è¯„æµ‹](#6-æ¨¡å‹è¯„æµ‹)
7. [å¸¸è§é—®é¢˜](#7-å¸¸è§é—®é¢˜)
8. [å‚è€ƒæ–‡çŒ®](#8-å‚è€ƒæ–‡çŒ®) ğŸ†•

---

## 1. æ¨¡å‹é€‰æ‹©

### ğŸ† æ¨èæ¨¡å‹å¯¹æ¯”

| æ¨¡å‹ | å‚æ•°é‡ | 3090æ˜¾å­˜å ç”¨ | ç‰¹ç‚¹ | æ¨èåº¦ |
|------|--------|--------------|------|--------|
| **Paraformer-large** | 220M | ~8GB(batch4000) | éè‡ªå›å½’ï¼Œé€Ÿåº¦å¿«ï¼Œç²¾åº¦é«˜ | â­â­â­â­â­ |
| SenseVoice-Small | 330M | ~12GB | å¤šåŠŸèƒ½(ASR+æƒ…æ„Ÿ) | â­â­â­â­ |
| Conformer-12e6d | ~100M | ~6GB | ç»å…¸æ¶æ„ï¼Œæ˜“è°ƒä¼˜ | â­â­â­ |
| Fun-ASR-Nano | 800M | >20GB | æœ€æ–°æœ€å¼ºï¼Œä½†æ— è®­ç»ƒä»£ç  | âŒ |

### âœ… æœ€ç»ˆé€‰æ‹©ï¼šParaformer-large

**ç†ç”±**ï¼š
- éè‡ªå›å½’æ¶æ„ï¼Œæ¨ç†é€Ÿåº¦å¿«10å€
- 220Må‚æ•°ï¼Œ3090å¯å…¨é‡å¾®è°ƒ
- Aishell1 test CER: 1.94%ï¼ˆSOTAæ°´å¹³ï¼‰
- 60000å°æ—¶ä¸­æ–‡é¢„è®­ç»ƒ
- å®Œæ•´çš„å¾®è°ƒä»£ç æ”¯æŒ

```bash
# ModelScope æ¨¡å‹ID
model_id="iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch"
```

---

## 2. ç¯å¢ƒé…ç½®

### 2.1 åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
```bash
conda create -n funasr python=3.10 -y
conda activate funasr
```

### 2.2 å®‰è£…ä¾èµ–
```bash
# PyTorch with CUDA
pip install torch==2.1.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121

# FunASR æ ¸å¿ƒ
pip install -U funasr modelscope

# å¯é€‰åŠ é€Ÿ
pip install deepspeed
```

### 2.3 éªŒè¯å®‰è£…
```python
from funasr import AutoModel
model = AutoModel(model="iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch")
print("Installation OK!")
```

### 2.4 æ¨¡å‹ä¸‹è½½ï¼ˆå¯é€‰ï¼ŒåŠ é€Ÿåç»­è®­ç»ƒï¼‰
```bash
# è‡ªåŠ¨ä¸‹è½½åˆ° ~/.cache/modelscope/
python -c "from funasr import AutoModel; AutoModel(model='iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch')"
```

---

## 3. æ•°æ®å‡†å¤‡

### 3.1 æ•°æ®æ ¼å¼
FunASR æ”¯æŒä¸¤ç§æ ¼å¼ï¼š

**JSONLæ ¼å¼ï¼ˆæ¨èï¼‰**ï¼š
```json
{"key": "utt_001", "source": "/path/to/audio.wav", "target": "è½¬å½•æ–‡æœ¬"}
```

**Kaldiæ ¼å¼**ï¼š
```
# wav.scp
utt_001 /path/to/audio.wav

# text.txt  
utt_001 è½¬å½•æ–‡æœ¬
```

### 3.2 æ‰§è¡Œæ•°æ®å‡†å¤‡
```bash
cd /root/CLEAR-VOX-MODEL
python scripts/prepare_1h_dataset.py
```

### 3.3 éªŒè¯æ•°æ®
```bash
# æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
ls -la data/1h_dataset/

# æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
cat data/1h_dataset/data_statistics.txt
```

### 3.4 1h æ•°æ®é›†ç»Ÿè®¡
| åˆ’åˆ† | è¯´è¯äººæ•° | è¯­éŸ³æ¡æ•° |
|------|----------|----------|
| è®­ç»ƒé›† | 35 | 45,327 |
| éªŒè¯é›† | 4 | 4,460 |
| æµ‹è¯•é›† | 5 | 6,064 |
| **æ€»è®¡** | **44** | **55,851** |

---

## 4. è®­ç»ƒé…ç½® âš ï¸ å·²æ ¡éªŒæ›´æ–°

### 4.1 å…³é”®å‚æ•°å¯¹æ¯”ï¼ˆå®˜æ–¹ vs 3090ä¼˜åŒ–ï¼‰

| å‚æ•° | å®˜æ–¹é»˜è®¤ | 3090ä¼˜åŒ– | è¯´æ˜ |
|------|----------|----------|------|
| batch_size | 6000 tokens | 4000-6000 | 3090å•å¡å¯å°è¯•6000 |
| **learning_rate** | **0.0002** | **0.0002** | âš ï¸ å®˜æ–¹æ¨èï¼Œæ¯”ä¹‹å‰0.0001æ›´é«˜ |
| max_epoch | 50 | 50-100 | å°æ•°æ®é›†å¯é€‚å½“å¢åŠ  |
| validate_interval | 2000 | 2000 | æ¯2000æ­¥éªŒè¯ |
| keep_nbest_models | 20 | 10 | 3090å­˜å‚¨ä¼˜åŒ– |
| **avg_nbest_model** | **10** | **10** | ğŸ†• æœ€ä½³Nä¸ªæ¨¡å‹å¹³å‡ |
| **sort_size** | **1024** | **1024** | ğŸ†• æ’åºç¼“å†²åŒºå¤§å° |
| **data_split_num** | **1** | **1** | æ•°æ®åˆ‡ç‰‡æ•°ï¼ˆå¤§æ•°æ®é›†å¯å¢å¤§ï¼‰ |

### 4.2 å®Œæ•´è®­ç»ƒè„šæœ¬ (v2.0)

```bash
#!/bin/bash
# /root/CLEAR-VOX-MODEL/scripts/finetune_paraformer.sh
# Version 2.0 - åŸºäºå®˜æ–¹é…ç½®æ ¡éªŒ

export CUDA_VISIBLE_DEVICES="0"

workspace=/root/CLEAR-VOX-MODEL
model="iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch"

train_data="${workspace}/data/1h_dataset/train.jsonl"
val_data="${workspace}/data/1h_dataset/val.jsonl"
output_dir="${workspace}/exp/paraformer_finetune_1h"

mkdir -p ${output_dir}

torchrun --nproc_per_node=1 \
${workspace}/funasr/bin/train_ds.py \
++model="${model}" \
++train_data_set_list="${train_data}" \
++valid_data_set_list="${val_data}" \
++dataset="AudioDataset" \
++dataset_conf.index_ds="IndexDSJsonl" \
++dataset_conf.data_split_num=1 \
++dataset_conf.batch_sampler="BatchSampler" \
++dataset_conf.batch_size=6000 \
++dataset_conf.sort_size=1024 \
++dataset_conf.batch_type="token" \
++dataset_conf.num_workers=4 \
++train_conf.max_epoch=50 \
++train_conf.log_interval=50 \
++train_conf.resume=true \
++train_conf.validate_interval=2000 \
++train_conf.save_checkpoint_interval=2000 \
++train_conf.keep_nbest_models=10 \
++train_conf.avg_nbest_model=10 \
++train_conf.use_deepspeed=false \
++optim_conf.lr=0.0002 \
++output_dir="${output_dir}" \
2>&1 | tee ${output_dir}/train.log
```

### 4.3 ä¸å®˜æ–¹é…ç½®å·®å¼‚è¯´æ˜

| é…ç½®é¡¹ | å®˜æ–¹å€¼ | æˆ‘ä»¬çš„å€¼ | åŸå›  |
|--------|--------|----------|------|
| CUDA_VISIBLE_DEVICES | "0,1" | "0" | 3090å•å¡ |
| batch_size | 6000 | 6000 | å®˜æ–¹æ¨è |
| learning_rate | 0.0002 | 0.0002 | âœ… å·²ä¿®æ­£ï¼Œå®˜æ–¹æ¨è |
| keep_nbest_models | 20 | 10 | èŠ‚çœå­˜å‚¨ |
| resume | true | true | æ”¯æŒæ–­ç‚¹ç»­è®­ |

---

## 5. æ‰§è¡Œè®­ç»ƒ

### 5.1 å¯åŠ¨è®­ç»ƒ
```bash
cd /root/CLEAR-VOX-MODEL
bash scripts/finetune_paraformer.sh
```

### 5.2 ç›‘æ§è®­ç»ƒ
```bash
# å®æ—¶æŸ¥çœ‹æ—¥å¿—
tail -f exp/paraformer_finetune_1h/train.log

# æŸ¥çœ‹GPUä½¿ç”¨
watch -n 1 nvidia-smi
```

### 5.3 è®­ç»ƒè¾“å‡º
```
exp/paraformer_finetune_1h/
â”œâ”€â”€ model.pt.ep0           # epoch 0 æ¨¡å‹
â”œâ”€â”€ model.pt.ep1           # epoch 1 æ¨¡å‹
â”œâ”€â”€ ...
â”œâ”€â”€ model.pt.avg_10        # æœ€ä½³10ä¸ªæ¨¡å‹å¹³å‡
â””â”€â”€ train.log              # è®­ç»ƒæ—¥å¿—
```

---

## 6. æ¨¡å‹è¯„æµ‹

### 6.1 æ¨ç†æµ‹è¯•
```bash
python scripts/inference_test.py \
  --model exp/paraformer_finetune_1h/model.pt.avg_10 \
  --test data/1h_dataset/test.jsonl \
  --output exp/paraformer_finetune_1h/test_results.json
```

### 6.2 åŸºçº¿å¯¹æ¯”
```bash
# æµ‹è¯•åŸå§‹æ¨¡å‹
python scripts/inference_test.py \
  --model "iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch" \
  --test data/1h_dataset/test.jsonl \
  --output exp/baseline_results.json
```

### 6.3 é¢„æœŸæ•ˆæœï¼ˆåŸºäºCDSDè®ºæ–‡å‚è€ƒï¼‰

| æ¨¡å‹ | é¢„æœŸ CER | è¯´æ˜ |
|------|----------|------|
| Paraformer-large (åŸå§‹) | 25-35% | æœªé€‚åº”æ„éŸ³éšœç¢ |
| Paraformer-large (å¾®è°ƒ) | 16-22% | å¾®è°ƒå |
| **CDSDè®ºæ–‡æœ€ä½³** | **16.4%** | Hybrid CTC/Attention |
| äººç±»è¯„ä¼°è€… | 20.45% | CDSDè®ºæ–‡äººç±»baseline |

> **æ³¨æ„**: å¾®è°ƒå CER ä¼˜äºäººç±»è¯„ä¼°è€… (20.45%) æ˜¯åˆç†ç›®æ ‡

---

## 7. å¸¸è§é—®é¢˜

### Q1: æ˜¾å­˜ä¸è¶³ (OOM)
```bash
# é™ä½batch_size
++dataset_conf.batch_size=4000
# æˆ–é™åˆ°2000
++dataset_conf.batch_size=2000
```

### Q2: æ¨¡å‹ä¸‹è½½å¤±è´¥
```bash
# ä½¿ç”¨é•œåƒ
export HF_ENDPOINT=https://hf-mirror.com
pip install -U modelscope -i https://mirror.sjtu.edu.cn/pypi/web/simple
```

### Q3: è®­ç»ƒä¸æ”¶æ•›
```bash
# é™ä½å­¦ä¹ ç‡ï¼ˆä½†å…ˆå°è¯•å®˜æ–¹0.0002ï¼‰
++optim_conf.lr=0.0001
# å¢åŠ warmup
++scheduler_conf.warmup_steps=1000
```

### Q4: æƒ³ä½¿ç”¨LoRAå¾®è°ƒ
ç›®å‰ FunASR åŸç”Ÿä¸æ”¯æŒ LoRAï¼Œéœ€ä½¿ç”¨ PEFT åº“ï¼š
```python
from peft import LoraConfig, get_peft_model
# éœ€è¦è‡ªå®šä¹‰è®­ç»ƒè„šæœ¬
```

### Q5: æ–­ç‚¹ç»­è®­
```bash
# å·²é…ç½® resume=trueï¼Œè‡ªåŠ¨ä»æœ€æ–°checkpointç»§ç»­
# å¦‚éœ€æŒ‡å®šcheckpoint:
++init_param="${output_dir}/model.pt.ep10"
```

---

## 8. å‚è€ƒæ–‡çŒ® ğŸ†•

### 8.1 CDSD æ•°æ®é›†è®ºæ–‡
> **CDSD: Chinese Dysarthria Speech Database**
> - ä¼šè®®: INTERSPEECH 2024
> - è§„æ¨¡: 133 å°æ—¶ï¼Œ44ä½è¯´è¯äºº
> - æœ€ä½³ç»“æœ: CER 16.4% (Hybrid CTC/Attention)
> - äººç±»åŸºçº¿: CER 20.45%
> - arXiv: https://arxiv.org/abs/2310.15930

### 8.2 FunASR æ¡†æ¶
> - GitHub: https://github.com/modelscope/FunASR
> - æ–‡æ¡£: https://funasr.readthedocs.io
> - ModelScope: https://modelscope.cn/models/iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch

### 8.3 Paraformer è®ºæ–‡
> **Paraformer: Fast and Accurate Parallel Transformer for Non-autoregressive End-to-End Speech Recognition**
> - arXiv: https://arxiv.org/abs/2206.08317

---

## ğŸ“Š è®­ç»ƒæµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FunASR æ„éŸ³éšœç¢ ASR å¾®è°ƒ v2.0                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  1. æ•°æ®å‡†å¤‡                                                    â”‚
â”‚     Audio + Text â†’ prepare_1h_dataset.py â†’ train/val/test.jsonlâ”‚
â”‚     â””â”€ 45,327 è®­ç»ƒ / 4,460 éªŒè¯ / 6,064 æµ‹è¯•                    â”‚
â”‚                                                                â”‚
â”‚  2. æ¨¡å‹é€‰æ‹©                                                    â”‚
â”‚     Paraformer-large (220M) â† æ¨è                             â”‚
â”‚                                                                â”‚
â”‚  3. è®­ç»ƒé…ç½® (v2.0 æ ¡éªŒå)                                       â”‚
â”‚     batch=6000, lr=0.0002, epoch=50, avg_nbest=10              â”‚
â”‚                                                                â”‚
â”‚  4. æ‰§è¡Œè®­ç»ƒ                                                    â”‚
â”‚     torchrun â†’ train_ds.py â†’ model.pt.avg_10                   â”‚
â”‚                                                                â”‚
â”‚  5. è¯„æµ‹                                                        â”‚
â”‚     inference_test.py â†’ CER% (ç›®æ ‡ < 20.45% äººç±»åŸºçº¿)           â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**ä½œè€…**: GitHub Copilot  
**æ—¥æœŸ**: 2025-12-23  
**ç‰ˆæœ¬**: v2.0 (åŸºäºå®˜æ–¹é…ç½®æ ¡éªŒ + CDSDè®ºæ–‡ä¼˜åŒ–)
